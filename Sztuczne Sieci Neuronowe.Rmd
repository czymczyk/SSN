
```{r}
library(neuralnet)
library(nnet)
```
+++
  tutaj opis danych
http://archive.ics.uci.edu/ml/datasets/seeds?fbclid=IwAR2M-BNinAA7kSe2h8GebuKJ02nGYjzSU3FwKtQmXrmltDZY2NQQODffJmA
+++
  
  ```{r}
data <- read.table("seeds.txt", sep = "\t")
names(data) <- c("area_A", 
                 "perimeter_P", 
                 "compactness_C", 
                 "length_of_kernel", 
                 "width_of_kernel", 
                 "asymmetry_coefficient", 
                 "length_of_kernel_groove", 
                 "label"
)
head(data)
```
rozdzielamy zmienna "label" na 3 zmienne binarne
```{r}
train <- cbind(data[, 1:7], class.ind(as.factor(data$label)))
names(train) <- c(names(data)[1:7],"K", "R", "C")
maximum<-apply(train[,1:7], 2, max)
minimum<-apply(train[,1:7], 2, min)
train2 <- as.data.frame(scale(train[, 1:7], center = minimum,scale=maximum-minimum))
train <- cbind(train2, train[,8:10])
train <- train[sample(1:210, 210),]
```

```{r}
n <- names(train)
f <- as.formula(paste("K + R + C ~", paste(n[!n %in% c("K", "R", "C")], collapse = " + ")))
f
outs <- NULL
```

funckja gdzie pod x wstawiamy konfiguracje neuronów w warstwie ukrytej
np
foo(c(3, 4))
sieć odpali się z 3 neuronami w pierwszej warstwie i 4 neuronami w drugiej warstwie
```{r}
#wartości domyślne c(3,4) jako neurony oraz logistic jako funkcja aktywacji 
xd <- function(x = c(3, 4), fct = "logistic")
{
  #ten for to walidacja krzyżowa
  for(i in 1:6)
  {
    index <- (((i-1) * round((1/6)*nrow(train))) + 1):((i*round((1/6) * nrow(train))))
    train_cv <- train[index, ]
    test_cv <- train[-index, ]
    nn_cv <- neuralnet(f,
                       data = train_cv,
                       hidden = x,
                       act.fct = fct,
                       linear.output = FALSE)
    
    
    pr.nn <- compute(nn_cv, test_cv[, 1:7])
    pr.nn_ <- pr.nn$net.result
    
    original_values <- max.col(test_cv[, 8:10])
    pr.nn_2 <- max.col(pr.nn_)
    outs[i] <- mean(pr.nn_2 == original_values)
  }
  a <- mean(outs)
  return(a)
}
```

```{r}
xd(c(4,3))
```

